{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batman', 'avengers']\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2019/12/05/movies/in-fabric-review.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2019/01/10/movies/and-breathe-normally-review-a-drama-that-humanizes-the-border.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2016/10/28/movies/finding-babel-review.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2015/01/23/movies/the-duke-of-burgundy-is-an-erotic-hothouse-flower.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2007/03/30/movies/30wedd.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2006/10/27/movies/27babe.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/2004/05/14/movies/film-review-inside-a-notorious-prison-fires-of-rage-and-regret.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1998/11/25/movies/film-review-goodbye-green-acres-hello-wild-side.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1996/11/22/movies/they-love-to-rock-as-hard-as-men-do.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1995/10/28/movies/film-review-letters-of-love-and-war.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1995/08/04/movies/film-review-a-feisty-pig-with-aspirations-beyond-the-sty.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1991/12/06/movies/review-film-saving-the-savages-but-losing-themselves.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1988/01/29/movies/film-from-germany-singing-the-blues-in-red.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1987/12/18/movies/film-ironweed-from-hector-babenco.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1985/07/26/movies/screen-babenco-s-kiss-of-the-spider-woman.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1981/05/05/movies/babenco-s-pixote-show-the-boys-of-brazil.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1970/10/02/archives/screen-story-of-a-student-filmmaker.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1968/03/28/archives/the-edge-begins-run.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1961/12/15/archives/disneys-babes-in-toyland-is-holiday-show-at-music-hall.html query Babe\n",
      "^^^^20^^Babe\n",
      "http://www.nytimes.com/1960/06/08/archives/screen-bardot-clothed-babette-goes-to-war-opens-at-the-paris.html query Babe\n",
      "^^^^3^^Carrington\n",
      "http://www.nytimes.com/1995/10/13/movies/film-festival-review-bloomsbury-s-many-kinds-of-love.html query Carrington\n",
      "^^^^3^^Carrington\n",
      "Content is still empty\n",
      "^^^^3^^Carrington\n",
      "http://www.nytimes.com/1955/08/02/archives/screen-court-martial-study-of-british-army-officer-in-trouble.html query Carrington\n",
      "^^^^1^^Dead Man Walking\n",
      "http://www.nytimes.com/1995/12/29/movies/film-review-a-condemned-killer-and-a-crusading-nun.html query Dead Man Walking\n",
      "^^^^1^^Across the Sea of Time\n",
      "http://www.nytimes.com/1995/10/20/movies/film-review-new-york-city-via-imax.html query Across the Sea of Time\n",
      "^^^^1^^It Takes Two\n",
      "http://www.nytimes.com/1995/11/17/movies/film-review-matchmaking-9-year-old-look-alikes.html query It Takes Two\n",
      "^^^^2^^Clueless\n",
      "http://www.nytimes.com/1995/07/19/movies/film-review-a-teen-ager-who-s-clear-on-her-priorities.html query Clueless\n",
      "^^^^2^^Clueless\n",
      "http://www.nytimes.com/1968/09/27/archives/alexander-kluge-presents-artists-under-the-big-top-perplexed.html query Clueless\n",
      "^^^^2^^Cry, the Beloved Country\n",
      "http://www.nytimes.com/1995/12/15/movies/film-review-searching-for-answers-in-yesterday-s-south-africa.html query Cry, the Beloved Country\n",
      "^^^^2^^Cry, the Beloved Country\n",
      "http://www.nytimes.com/1952/01/24/archives/the-screen-in-review-alan-patons-cry-the-beloved-country-with.html query Cry, the Beloved Country\n",
      "^^^^3^^Richard III\n",
      "http://www.nytimes.com/1996/01/14/movies/film-taking-the-children-two-on-the-lam-plus-a-matisse-067164.html query Richard III\n",
      "^^^^3^^Richard III\n",
      "http://www.nytimes.com/1986/06/22/movies/home-video-new-cassettes-from-shakespeare-to-pop-soul-661486.html query Richard III\n",
      "^^^^3^^Richard III\n",
      "http://www.nytimes.com/1956/03/12/archives/tv-another-milestone-debut-of-richard-iii-on-home-screen-is.html query Richard III\n",
      "^^^^1^^Dead Presidents\n",
      "http://www.nytimes.com/1995/09/29/movies/film-festival-review-the-evolution-of-a-very-confused-young-man.html query Dead Presidents\n",
      "^^^^1^^Restoration\n",
      "http://www.nytimes.com/1995/12/29/movies/film-review-the-king-s-vet-beard-and-cuckolder.html query Restoration\n"
     ]
    }
   ],
   "source": [
    "import pprint \n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from types import SimpleNamespace\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "def writeToCSV(query_term, icount):\n",
    "    secret = \"7sfsQiTVkLW6tv46UeQicplv8snUjbJZ\"\n",
    "\n",
    "    # Define the endpoint \n",
    "\n",
    "    url = 'https://api.nytimes.com/svc/movies/v2/reviews/search.json'\n",
    "    # Specify the query and \n",
    "    # number of returns \n",
    "    sleep(0.06)\n",
    "    # Make the request\n",
    "    url = url + \"?query=\"+query_term+\"&api-key=\"+secret+\"&num_results=50\"\n",
    "    response = requests.get(url)\n",
    "    #print(str(url))\n",
    "    response_json = response.json()\n",
    "    #print(str(response_json))\n",
    "    # fields = ('Title', 'Content', 'URL')\n",
    "    wikifile = open(\"movie_reviews.csv\",mode='a', newline='')\n",
    "    # wikifile = csv.DictWriter(\"news_article.csv\", fieldnames=fields, lineterminator = '\\n')\n",
    "    \n",
    "\n",
    "    MyFile=open('ExpandedListMovies.txt','r')\n",
    "    expanded = []\n",
    "    lines = MyFile.read().splitlines()\n",
    "    for x in lines:\n",
    "        expanded.append(x+\"\\n\")\n",
    "    MyFile.close()\n",
    "    tempicount = icount\n",
    "    if('results' in response_json and response_json['results'] and len(response_json['results']) and response_json['results'][0]):\n",
    "        for i in range(len(response_json['results'])):\n",
    "            print(\"^^^^\"+str(len(response_json['results']))+\"^^\"+query_term)\n",
    "            if(response_json['results'][i] == None or 'link' not in response_json['results'][i] or response_json['results'][i]['link'] == None or 'url' not in response_json['results'][i]['link']):\n",
    "                print(\"Format does not contain link and results\")\n",
    "                continue\n",
    "            url = response_json['results'][i]['link']['url']\n",
    "            #print(\"Writing in 1 ---------- \"+str(i))\n",
    "            if url+\"\\n\" in expanded:\n",
    "                print(str(url) + \" query \" + query_term)\n",
    "                continue\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            title = soup.title.text # gets you the text of the <title>(...)</title>\n",
    "\n",
    "            if(len(soup.select('article')) <= 0 or len(soup.select('article')[0].select('section')) <=0):\n",
    "                print(\"No articles found (maybe!)\")\n",
    "                continue\n",
    "\n",
    "            content = \"\"\n",
    "            #print(str(soup.select('article')[0].select('section')))\n",
    "            section_content = soup.select('article')[0].select('section')\n",
    "            if(section_content and len(section_content)>0):\n",
    "                for sect_itr in range(len(section_content)):\n",
    "                    if(\"@media\" in str(section_content[sect_itr]) or \"<style>\" in str(section_content[sect_itr]) or \"Full text is unavailable for this digitized archive article\" in str(section_content[sect_itr])):\n",
    "                        continue\n",
    "                    content = section_content[sect_itr].text\n",
    "                    break\n",
    "            if(content == \"\"):\n",
    "                print(\"Content is still empty\")\n",
    "                continue\n",
    "\n",
    "            if(\"@media\" in content or \"<style>\" in content or \"Full text is unavailable for this digitized archive article\" in content):\n",
    "                print(\"Could not find article\")\n",
    "                continue\n",
    "\n",
    "            if(len(content) < 750):\n",
    "                print(\"Too Short\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            div_tag = \"\"\n",
    "            figure_tag = \"\"\n",
    "            figure_caption_tag = \"\"\n",
    "            img_tag = \"\"\n",
    "\n",
    "            if(\"—\" in str(content)):\n",
    "                index = content.index(\"—\")\n",
    "                content = content[index+1:len(content)]\n",
    "            if(len(soup.select('article')) >0 and len(soup.select('article')[0].select('section')) >0 and (soup.select('article')[0].select('section')[0].div!=None)):\n",
    "                div_tag = soup.select('article')[0].select('section')[0].div.text\n",
    "                # for i in range(len(soup.select('article')[0].select('section')[0].select('div')))\n",
    "                    # content = content.replace(soup.select('article')[0].select('section')[0].select('div')[i].text, \"\")\n",
    "\n",
    "            if(len(soup.select('article')) >0 and len(soup.select('article')[0].select('section')) >0 and soup.select('article')[0].select('section')[0].figure!=None):\n",
    "                figure_tag = soup.select('article')[0].select('section')[0].figure.text\n",
    "                for i in range(len(soup.select('article')[0].select('section')[0].select('figure'))):\n",
    "                    content = content.replace(soup.select('article')[0].select('section')[0].select('figure')[i].text, \"\")\n",
    "\n",
    "            if(len(soup.select('article')) >0 and len(soup.select('article')[0].select('section')) >0 and soup.select('article')[0].select('section')[0].figcaption!=None):\n",
    "                figure_caption_tag = soup.select('article')[0].select('section')[0].figcaption.text\n",
    "                for i in range(len(soup.select('article')[0].select('section')[0].select('figcaption'))):\n",
    "                    content = content.replace(soup.select('article')[0].select('section')[0].select('figcaption')[i].text, \"\")\n",
    "\n",
    "            if(len(soup.select('article')) >0 and len(soup.select('article')[0].select('section')) >0 and soup.select('article')[0].select('section')[0].img!=None):\n",
    "                img_tag = soup.select('article')[0].select('section')[0].img.text\n",
    "                for i in range(len(soup.select('article')[0].select('section')[0].select('img'))):\n",
    "                    content = content.replace(soup.select('article')[0].select('section')[0].select('img')[i].text, \"\")\n",
    "\n",
    "            content = content.replace(\"\\n\",\" \")\n",
    "            content = content.replace(\"Getty Images\", \"\")\n",
    "            #print(\"Writing in 4\")\n",
    "            x = re.findall(\"\\s\\s+\", content)\n",
    "            for s in x:\n",
    "                content = content.replace(s,\" \")\n",
    "\n",
    "            x = re.findall(\"\\.[A-Z]\", content)\n",
    "            for h in x:\n",
    "                content = content.replace(h,h[0]+\" \"+h[1])\n",
    "\n",
    "            x = re.findall(\"\\.“\", content)\n",
    "            for h in x:\n",
    "                content = content.replace(h,h[0]+\" \"+h[1])\n",
    "\n",
    "            x = re.findall(\"\\.”[A-Z]\", content)\n",
    "            for h in x:\n",
    "                content = content.replace(h,h[0]+h[1]+\" \"+h[2])\n",
    "\n",
    "            # content = content.replace(div_tag, \"\")\n",
    "            # content = content.replace(figure_tag, \"\")\n",
    "            # content = content.replace(figure_caption_tag, \"\")\n",
    "            # content = content.replace(img_tag, \"\")\n",
    "\n",
    "            print(\"Writing in CSV******* \" + str(tempicount))\n",
    "            content = content.strip()\n",
    "            \n",
    "            wikiwriter = csv.writer(wikifile, delimiter=',')\n",
    "            try:\n",
    "                wikiwriter.writerow([title,content,url])\n",
    "                tempicount = tempicount+1\n",
    "\n",
    "            except UnicodeEncodeError:\n",
    "                print(\"UnicodeEncodeError!\")\n",
    "                continue\n",
    "            except JSONDecodeError:\n",
    "                print(\"JSONDecodeError!\")\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                print(\"AttributeError!\")\n",
    "                continue\n",
    "            \n",
    "            expanded.append(url+\"\\n\")\n",
    "            if(tempicount == 20000):\n",
    "                    break\n",
    "\n",
    "            \n",
    "\n",
    "    wikifile.close()\n",
    "    MyFile=open('ExpandedListMovies.txt','w')\n",
    "    MyFile.writelines(expanded)\n",
    "    MyFile.close()\n",
    "    return tempicount\n",
    "\n",
    "search_terms_file=open('movie_terms.txt','r')\n",
    "query_list = search_terms_file.read().splitlines()\n",
    "query_test = [\"batman\",\"avengers\"]\n",
    "icount = 0\n",
    "for i in range(len(query_list)):\n",
    "    icount = writeToCSV(query_list[i], icount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batman', 'avengers']\n"
     ]
    }
   ],
   "source": [
    "search_terms_file=open('movie_terms.txt','r')\n",
    "lines = search_terms_file.read().splitlines()\n",
    "print(str(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
