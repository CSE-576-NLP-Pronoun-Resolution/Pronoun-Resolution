{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Contextual_Embeddings_usingBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaxXdCJPdYZW"
      },
      "source": [
        "In this Notebook, we aim to learn the contextual embeddings for the Pronoun, and its possible resolutions from the sentence  and frame the Pronoun resolution task as a Supervised Classification task.\n",
        "\n",
        "\n",
        "---\n",
        "We obtain the contextual embeddings using BERT and feed this embeddings to a classifier to obtain results.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "The performance of the model has been tested with GAP dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxeQ6oxLXnPO"
      },
      "source": [
        "# !wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suoJYqqeXMEY"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForPreTraining\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Amh2V-f2Ay"
      },
      "source": [
        "\n",
        "def run_bert(data):\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  model = TFBertForPreTraining.from_pretrained('bert-base-uncased',output_hidden_states = True)\n",
        "\n",
        "  index = data.index\n",
        "  columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n",
        "  emb = pd.DataFrame(index = index, columns = columns)\n",
        "  emb.index.name = \"ID\"\n",
        "  # print('Length of data__________________',len(data))\n",
        "  for rowidx in range(0,len(data)):\n",
        "    \n",
        "    text = data.loc[rowidx,'Text']\n",
        "    \n",
        "    input_ids = tf.constant(tokenizer.encode(text, add_special_tokens=True))[None, :]  # Batch size 1\n",
        "    \n",
        "    # Tokenize our sentence with the BERT tokenizer.\n",
        "    tokenized_text = tokenizer.tokenize(text)\n",
        "  \n",
        "    # Print out the tokens.\n",
        "    # print(tokenized_text)\n",
        "\n",
        "    outputs = model(input_ids)\n",
        "    hidden_states = outputs[2] # Taking the hidden layers\n",
        "\n",
        "    A = data.loc[rowidx,'A'].lower()\n",
        "    # print('A---------',A)\n",
        "    B = data.loc[rowidx,'B'].lower()\n",
        "    # print('B---------',B)\n",
        "    P = data.loc[rowidx,'Pronoun'].lower()\n",
        "    # print('P---------',P,'\\n')\n",
        "\n",
        "    A_embedding = np.zeros(768)\n",
        "    B_embedding = np.zeros(768)\n",
        "    P_embedding = np.zeros(768)\n",
        "\n",
        "    #print([A_embedding,B_embedding,P_embedding])\n",
        "\n",
        "    A_count = 0   # Used to take average if there are more than one occurence of A in a single sentence\n",
        "    B_count = 0   # Used to take average if there are more than one occurence of B in a single sentence\n",
        "    P_count = 0   # Used to take average if there are more than one occurence of P in a single sentence\n",
        "\n",
        "\n",
        "    for layers in range(1,len(hidden_states)):\n",
        "      for sentences in hidden_states[layers]:\n",
        "        idx = 0\n",
        "        for tokens in range(1,len(sentences)-1):\n",
        "          tok = tokenized_text[idx].strip('#')\n",
        "          idx = idx + 1\n",
        "          tok = tok.lower()\n",
        "          #if(rowidx == 4):\n",
        "            #print(tok)\n",
        "          if tok in A:\n",
        "            #print(sentences[tokens])\n",
        "            if(A.index(tok) > 0): # check for firstname and last name\n",
        "              continue\n",
        "\n",
        "            A_embedding += sentences[tokens]  # calculating the embedding for A\n",
        "            A_count += 1\n",
        "\n",
        "          if tok in B:\n",
        "            #print(sentences[tokens])\n",
        "            if(B.index(tok) > 0):\n",
        "              continue\n",
        "\n",
        "            B_embedding += sentences[tokens]  # calculating the embedding for B\n",
        "            B_count += 1\n",
        "\n",
        "          if tok in P:\n",
        "            if(P.index(tok) > 0):\n",
        "              continue\n",
        "            P_embedding += sentences[tokens]  # calculating the embedding for P\n",
        "            P_count += 1\n",
        "\n",
        "    #if(rowidx == 4):\n",
        "   #   print('Inside A_____________',A_count)\n",
        "    # print('Inside A_____________',A_embedding)\n",
        "    A_embedding /= A_count\n",
        "    \n",
        "    #if(rowidx == 4):\n",
        "     # print('Inside B_____________',B_count)\n",
        "    # print('Inside B_____________',B_embedding)\n",
        "    B_embedding /= B_count\n",
        "\n",
        "   # if(rowidx == 4):\n",
        "    #  print('Inside P_____________',P_count)\n",
        "    # print('Inside P_____________',P_embedding)\n",
        "    P_embedding /= P_count\n",
        "      \n",
        "    label = \"Neither\"\n",
        "    if (data.loc[rowidx,\"A-Coref\"] == True):\n",
        "      label = \"A\"\n",
        "    if (data.loc[rowidx,\"B-Coref\"] == True):\n",
        "      label = \"B\"\n",
        "    A_embedding = np.array(A_embedding)\n",
        "    B_embedding = np.array(B_embedding)\n",
        "    P_embedding = np.array(P_embedding)\n",
        "    # print(A_embedding.shape, B_embedding.shape,P_embedding.shape)\n",
        "\n",
        "    emb.iloc[rowidx] = [A_embedding,B_embedding,P_embedding,label]\n",
        "\n",
        "  return emb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sGCD_2PaT3x",
        "outputId": "2037e01b-b0f2-4dc0-cd78-cdc79df3e9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = pd.read_csv('/content/Cleaned_Dataset.csv')\n",
        "data = data.drop('Unnamed: 10',axis=1)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-Coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-Coref</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>After the war, Herbert attended the University...</td>\n",
              "      <td>he</td>\n",
              "      <td>8</td>\n",
              "      <td>Herbert</td>\n",
              "      <td>16</td>\n",
              "      <td>True</td>\n",
              "      <td>Beverly</td>\n",
              "      <td>76</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Herbert was appalled to learn of senator McCar...</td>\n",
              "      <td>he</td>\n",
              "      <td>140</td>\n",
              "      <td>Herbert</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>McCarthy</td>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Herbert has attracted a sometimes fanatical fa...</td>\n",
              "      <td>he</td>\n",
              "      <td>98</td>\n",
              "      <td>Herbert</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>Herbert</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>In 1887, after the death of his brother and a ...</td>\n",
              "      <td>he</td>\n",
              "      <td>17</td>\n",
              "      <td>Norris</td>\n",
              "      <td>75</td>\n",
              "      <td>False</td>\n",
              "      <td>Julian</td>\n",
              "      <td>99</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The publication of Buechner's third novel, The...</td>\n",
              "      <td>he</td>\n",
              "      <td>2</td>\n",
              "      <td>Buechner</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>Buechner</td>\n",
              "      <td>20</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                               Text  ... B-offset  B-Coref\n",
              "0   0  After the war, Herbert attended the University...  ...       76    False\n",
              "1   1  Herbert was appalled to learn of senator McCar...  ...       42    False\n",
              "2   2  Herbert has attracted a sometimes fanatical fa...  ...        1    False\n",
              "3   3  In 1887, after the death of his brother and a ...  ...       99     True\n",
              "4   4  The publication of Buechner's third novel, The...  ...       20    False\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAiris6ggd-a",
        "outputId": "acc359ef-bf44-4e73-b41d-88374ec2c3aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1He7a_kzaeFe",
        "outputId": "f79c8bf6-4d28-4702-b03a-e256979bdfdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "train_data = data[:4930]\n",
        "print(len(train_data))\n",
        "test_data = data[4930:]\n",
        "print(len(test_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4930\n",
            "1640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQp3yNLgaOQ5"
      },
      "source": [
        "train_emb = run_bert(train_data)\n",
        "train_emb.to_json(\"Bert_embs_train.json\", orient = 'columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbqcG7vZNAV-",
        "outputId": "466118d1-2fea-45c4-db26-21a1edf53f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "test_data = test_data.reset_index(drop=True)\n",
        "test_data.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-Coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-Coref</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3300</td>\n",
              "      <td>Mankiewicz's film of Anthony's Sleuth, which T...</td>\n",
              "      <td>he</td>\n",
              "      <td>47</td>\n",
              "      <td>Mankiewicz</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>Anthony</td>\n",
              "      <td>22</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4167</td>\n",
              "      <td>Despite his misgivings about its defensibility...</td>\n",
              "      <td>he</td>\n",
              "      <td>93</td>\n",
              "      <td>Johnston</td>\n",
              "      <td>49</td>\n",
              "      <td>True</td>\n",
              "      <td>Beauregard</td>\n",
              "      <td>68</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1659</td>\n",
              "      <td>In September 2008, on the eve of the Labour Pa...</td>\n",
              "      <td>she</td>\n",
              "      <td>86</td>\n",
              "      <td>Rowling</td>\n",
              "      <td>63</td>\n",
              "      <td>True</td>\n",
              "      <td>Gordon</td>\n",
              "      <td>177</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4391</td>\n",
              "      <td>Wagner had to flee, first visiting Paris and t...</td>\n",
              "      <td>he</td>\n",
              "      <td>47</td>\n",
              "      <td>Wagner</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>Alexander ller</td>\n",
              "      <td>115</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4392</td>\n",
              "      <td>Wagner scholars have argued that Schopenhauer'...</td>\n",
              "      <td>he</td>\n",
              "      <td>147</td>\n",
              "      <td>Wagner</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>Schopenhauer</td>\n",
              "      <td>34</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID                                               Text  ... B-offset  B-Coref\n",
              "0  3300  Mankiewicz's film of Anthony's Sleuth, which T...  ...       22    False\n",
              "1  4167  Despite his misgivings about its defensibility...  ...       68    False\n",
              "2  1659  In September 2008, on the eve of the Labour Pa...  ...      177    False\n",
              "3  4391  Wagner had to flee, first visiting Paris and t...  ...      115    False\n",
              "4  4392  Wagner scholars have argued that Schopenhauer'...  ...       34    False\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGoByaaAbbE8"
      },
      "source": [
        "test_emb = run_bert(test_data)\n",
        "test_emb.to_json(\"bert_ebms_test.json\", orient = 'columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASHdXpqymVTN",
        "outputId": "9a159fa0-ff05-41fa-fd9a-08316fa2df92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install xgboost\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un7Cm38KcWPB"
      },
      "source": [
        "## XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kARfqUlP2dJB"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ0wA3lAiclS"
      },
      "source": [
        "def parse_json(embeddings):\n",
        "  embeddings.sort_index(inplace = True)\n",
        "  X = np.zeros((len(embeddings),3*768))\n",
        "  Y = np.zeros((len(embeddings), 3))\n",
        "  label = embeddings[\"label\"]\n",
        "  # Concatenate features\n",
        "  for i in range(len(embeddings)):\n",
        "    A = np.array(embeddings.loc[i,\"emb_A\"])\n",
        "    B = np.array(embeddings.loc[i,\"emb_B\"])\n",
        "    P = np.array(embeddings.loc[i,\"emb_P\"])\n",
        "    X[i] = np.concatenate((A,B,P))\n",
        "    if np.sum(np.isnan(X[i])):\n",
        "      del label[i]\n",
        "\n",
        "  \n",
        "  remove_test  = [row for row in range(len(X)) if np.sum(np.isnan(X[row]))]\n",
        "  X = np.delete(X, remove_test, 0)\n",
        "  return X, label"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBYv0-jBbWQh"
      },
      "source": [
        "test = pd.read_json(\"/content/Bert_embs_test.json\")\n",
        "X_test, Y_test = parse_json(test)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmBb7IrMbW4p"
      },
      "source": [
        "training_data = pd.read_json(\"/content/Bert_embs_train.json\")\n",
        "X_train, Y_train = parse_json(training_data)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6_u83zVgyTg",
        "outputId": "ad365748-f670-4cd5-9d39-c25cf36bcf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(X_train),len(Y_train))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4688 4688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugRmI-5vN1gX",
        "outputId": "5316a0a2-c92e-4762-ef78-50d4998abb87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = XGBClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 77.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhR9Pya2mOQ7",
        "outputId": "58b90d17-00b1-4162-ae58-19eca39a2e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['A', 'B']\n",
        "print(classification_report(Y_test, y_pred, target_names=target_names))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.81      0.89      0.84      1062\n",
            "           B       0.69      0.55      0.61       500\n",
            "\n",
            "    accuracy                           0.78      1562\n",
            "   macro avg       0.75      0.72      0.73      1562\n",
            "weighted avg       0.77      0.78      0.77      1562\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chLeC_b3R7LG"
      },
      "source": [
        "import pickle\n",
        "filename = 'CompleteXGB.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ6aA22ZYV-r"
      },
      "source": [
        "# Testing on GAP data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31az9-OsYPMm",
        "outputId": "b678d28f-8ba0-41f6-e1c4-e0fad9c4ec8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-10 22:58:24--  https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1075889 (1.0M) [text/plain]\n",
            "Saving to: ‘gap-test.tsv’\n",
            "\n",
            "gap-test.tsv        100%[===================>]   1.03M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-11-10 22:58:24 (20.5 MB/s) - ‘gap-test.tsv’ saved [1075889/1075889]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajfe06DcYbTP",
        "outputId": "a24817e2-8cbc-490f-957b-b83e804a12ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "gap_data = pd.read_csv('/content/gap-test.tsv',sep = '\\t')\n",
        "gap_data = gap_data.rename(columns={\"A-coref\": \"A-Coref\", \"B-coref\": \"B-Coref\"})\n",
        "gap_data.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-Coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-Coref</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test-1</td>\n",
              "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
              "      <td>His</td>\n",
              "      <td>383</td>\n",
              "      <td>Bob Suter</td>\n",
              "      <td>352</td>\n",
              "      <td>False</td>\n",
              "      <td>Dehner</td>\n",
              "      <td>366</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test-2</td>\n",
              "      <td>Between the years 1979-1981, River won four lo...</td>\n",
              "      <td>him</td>\n",
              "      <td>430</td>\n",
              "      <td>Alonso</td>\n",
              "      <td>353</td>\n",
              "      <td>True</td>\n",
              "      <td>Alfredo Di St*fano</td>\n",
              "      <td>390</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test-3</td>\n",
              "      <td>Though his emigration from the country has aff...</td>\n",
              "      <td>He</td>\n",
              "      <td>312</td>\n",
              "      <td>Ali Aladhadh</td>\n",
              "      <td>256</td>\n",
              "      <td>True</td>\n",
              "      <td>Saddam</td>\n",
              "      <td>295</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test-4</td>\n",
              "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
              "      <td>his</td>\n",
              "      <td>526</td>\n",
              "      <td>Alliata</td>\n",
              "      <td>377</td>\n",
              "      <td>False</td>\n",
              "      <td>Pisciotta</td>\n",
              "      <td>536</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test-5</td>\n",
              "      <td>It is about a pair of United States Navy shore...</td>\n",
              "      <td>his</td>\n",
              "      <td>406</td>\n",
              "      <td>Eddie</td>\n",
              "      <td>421</td>\n",
              "      <td>True</td>\n",
              "      <td>Rock Reilly</td>\n",
              "      <td>559</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  ...                                             URL\n",
              "0  test-1  ...      http://en.wikipedia.org/wiki/Jeremy_Dehner\n",
              "1  test-2  ...    http://en.wikipedia.org/wiki/Norberto_Alonso\n",
              "2  test-3  ...           http://en.wikipedia.org/wiki/Aladhadh\n",
              "3  test-4  ...  http://en.wikipedia.org/wiki/Gaspare_Pisciotta\n",
              "4  test-5  ...            http://en.wikipedia.org/wiki/Chasers\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy7VO7AIZGbs",
        "outputId": "13fae80a-ed1f-48b1-f6ef-edc9ad35626e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gap_test = run_bert(gap_data)\n",
        "gap_test.to_json(\"gap_test.json\", orient = 'columns')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForPreTraining.\n",
            "\n",
            "All the layers of TFBertForPreTraining were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForPreTraining for predictions without further training.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM3P-AuEZRPD"
      },
      "source": [
        "gap_test_data = pd.read_json(\"/content/gap_test.json\")\n",
        "GX_test, GY_test = parse_json(gap_test_data)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17eoFdaCa52g",
        "outputId": "b10c1170-82af-4d36-e6dc-e97784f04e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gy_pred = model.predict(GX_test)\n",
        "accuracy = accuracy_score(GY_test, gy_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 54.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K7h2p1MbNii",
        "outputId": "223c5ba8-05c8-4caf-bab7-ab370a26fdf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['A', 'B','Neither']\n",
        "print(classification_report(GY_test, gy_pred, target_names=target_names))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.57      0.59      0.58       879\n",
            "           B       0.53      0.65      0.58       831\n",
            "     Neither       0.00      0.00      0.00       213\n",
            "\n",
            "    accuracy                           0.55      1923\n",
            "   macro avg       0.37      0.41      0.39      1923\n",
            "weighted avg       0.49      0.55      0.51      1923\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv-MxXMmbUig"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}